# CH07 支持向量机

本章概要部分比较精简, 多刷几遍.

[TOC]

## 前言

本章目录结构
1. [理论]线性可分支持向量机与硬间隔最大化
	1. 线性可分支持向量机
	1. 函数间隔和几何间隔
	1. 间隔最大化
	1. 学习的对偶算法
1. [理论]线性支持向量机与软间隔最大化
	1. 线性支持向量机
	1. 学习的对偶算法
	1. 支持向量
	1. 合页损失函数
1. [理论]非线性支持向量机与核函数
	1. 核技巧
	1. 正定核
	1. 常用核函数 
	1. 非线性支持向量分类机
1. [实现]序列最小最优化算法
	1. 两个变量二次规划的求解方法
	1. 变量的选择方法
	1. SMO算法

支持向量机是一种二类分类模型。

- **基本模型**是定义在特征空间上的间隔最大的**线性分类器**

- 支持向量机还包括**核技巧**， 这使它称为实质上的**非线性分类器**。

- 支持向量机学习策略是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。
- 判别模型

## [1] 线性可分支持向量机

### 问题描述

$$
\begin{align}
&\min_{w,b}\frac{\hat \gamma}{\left\|w\right\|}\\
&s.t.\ \ \ y_i(w\cdot x_i+b)-1\geqslant0,i=1,2,\dots,N\\
\end{align}
$$



这是个凸二次规划问题.

如果求出了上述方程的解$w^*, b^*$，就可得到

分离超平面
$$
w^*\cdot x+b^*=0
$$




相应的分类决策函数
$$
f(x)=sign(w^*\cdot x+b^*)
$$

### 函数间隔

对于给定数据集$T$和超平面$(w,b)$，定义超平面$(w,b)$关于样本点$(x_i,y_i)$的函数间隔为
$$
\hat \gamma_i=y_i(w\cdot x_i+b)
$$
定义超平面$(w,b)$关于训练数据集$T$的函数间隔为超平面$(w,b)$关于$T$中所有样本点$(x_i,y_i)$的函数间隔之最小值，即
$$
\hat \gamma=\min_{i=1,\cdots,N}\hat\gamma_i
$$
函数间隔可以表示分类预测的**正确性**及**确信度**。

### 几何间隔



### 间隔最大化



### 支持向量和间隔边界

由于支持向量在确定分离超平面中起着决定作用，所以将这种分类模型称为支持向量机。



对于任意线性可分的两组点，他们在分类超平面上的投影都是线性不可分的。

## [2] 线性支持向量机



## [3]非线性支持向量机

### 核函数



## 学习算法：序列最小最优化



## 扩展

### 对比支持向量机和提升方法



## 参考

